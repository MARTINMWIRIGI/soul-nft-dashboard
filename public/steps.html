<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Cultural Vault ‚Äî Steps Recording Layer</title>

  <!-- Tailwind for layout (optional) -->
  <script src="https://cdn.tailwindcss.com"></script>

  <!-- MediaPipe Pose -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5/pose.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

  <style>
    :root{
      --bg:#041025; --muted:#94a3b8; --glow1: #7c3aed; --glow2:#06b6d4;
    }
    body{ background:var(--bg); color:#f1f5f9; font-family:Inter,ui-sans-serif,system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial; -webkit-font-smoothing:antialiased; -moz-osx-font-smoothing:grayscale; }
    .capsule{ background:rgba(255,255,255,0.02); border:1px solid rgba(255,255,255,0.05); border-radius:1rem; }
    .glow-grid{
      background:
        repeating-linear-gradient(90deg, rgba(124,58,237,0.08) 0, rgba(124,58,237,0.08) 2px, transparent 2px, transparent 36px),
        repeating-linear-gradient(0deg, rgba(6,182,212,0.06) 0, rgba(6,182,212,0.06) 2px, transparent 2px, transparent 36px);
      position:relative; overflow:hidden;
      box-shadow: inset 0 0 40px rgba(124,58,237,0.02);
    }
    @keyframes gridGlow { from{opacity:0.6} to{opacity:1} }

    /* foot pulse */
    .footstep{
      position:absolute; width:44px; height:44px; border-radius:50%;
      background: radial-gradient(circle, rgba(124,58,237,0.9), rgba(6,182,212,0.35), transparent 60%);
      pointer-events:none; transform:translate(-50%,-50%); /* center at coords */
      animation:pulseStep 1.6s ease-out forwards;
      mix-blend-mode:screen;
      box-shadow: 0 6px 22px rgba(124,58,237,0.25);
    }
    @keyframes pulseStep{
      0%{ transform: translate(-50%,-50%) scale(0.45); opacity:0.95; }
      65%{ transform: translate(-50%,-50%) scale(1.15); opacity:0.45; }
      100%{ transform: translate(-50%,-50%) scale(1.6); opacity:0; }
    }

    /* trace canvas styling */
    #traceCanvas{ position:absolute; left:0; top:0; width:100%; height:100%; pointer-events:none; }

    /* UI tweaks */
    .btn { border-radius:9999px; padding:10px 18px; font-weight:600; cursor:pointer; border:none; }
    .btn-cta { background: linear-gradient(90deg,var(--glow1),var(--glow2)); color:white; box-shadow:0 6px 28px rgba(124,58,237,0.3); }
    .btn-muted { background:#0b1220; color:#cbd5e1; border:1px solid rgba(255,255,255,0.04); }
    .capsule-card{ background: linear-gradient(145deg, rgba(124,58,237,0.06), rgba(6,182,212,0.04)); border-radius:1rem; padding:16px; border:1px solid rgba(255,255,255,0.06); box-shadow: 0 8px 30px rgba(2,6,23,0.6); }

    pre.json-preview{ background: rgba(0,0,0,0.35); border:1px solid rgba(255,255,255,0.06); border-radius:8px; padding:12px; color:#cbd5e1; font-size:0.85rem; white-space:pre-wrap; max-height:220px; overflow:auto; }
    .muted { color:var(--muted); }
    .dot { width:10px; height:10px; border-radius:50%; background:var(--glow1); display:inline-block; margin-right:8px; box-shadow:0 6px 18px rgba(124,58,237,0.25); vertical-align:middle; }
    .gallery-card{ border-radius:12px; background: linear-gradient(180deg, rgba(255,255,255,0.02), rgba(255,255,255,0.01)); padding:12px; border:1px solid rgba(255,255,255,0.04); }
  </style>
</head>
<body class="min-h-screen flex flex-col items-center py-8 px-4">

<main class="w-full max-w-5xl space-y-8">

  <!-- Intro -->
  <section class="capsule p-6 text-center">
    <h1 class="text-3xl font-bold">üåå Steps Into Eternity</h1>
    <p class="text-lg muted mt-2">Every step carries memory. Record the rhythm of your presence.</p>
    <p class="muted mt-3">Move as you would in ritual, in dance, in celebration ‚Äî the vault will remember the pattern of your feet and translate it into a choreography map that can be minted and preserved.</p>
    <div class="mt-5 flex justify-center gap-3">
      <button id="startBtn" class="btn btn-cta">Begin Step Recording</button>
      <button id="stopBtn" class="btn btn-muted" disabled>Stop & Save</button>
      <button id="clearBtn" class="btn btn-muted" title="Clear current trace">Clear Trace</button>
    </div>
  </section>

  <!-- Recording Stage -->
  <section id="stage" class="capsule p-4 hidden">
    <div class="flex items-center justify-between mb-4">
      <div>
        <h2 class="text-2xl font-semibold">üé• The Ritual of Movement</h2>
        <p class="muted">Dance, walk, step ‚Äî the floor remembers.</p>
      </div>
      <div class="muted text-sm">Status: <span id="statusText">Idle</span></div>
    </div>

    <div class="relative glow-grid rounded-lg overflow-hidden" style="height:420px;">
      <!-- camera feed -->
      <video id="video" autoplay playsinline muted style="width:100%; height:100%; object-fit:cover; border-radius:10px;"></video>

      <!-- trace canvas -->
      <canvas id="traceCanvas"></canvas>

      <!-- footsteps overlay (DOM pulses) -->
      <div id="stepsOverlay" style="position:absolute; inset:0; pointer-events:none;"></div>

      <!-- countdown -->
      <div style="position:absolute; inset:0; display:flex; align-items:center; justify-content:center;">
        <div id="countdown" style="font-size:48px; font-weight:700; color:rgba(124,58,237,0.9);"></div>
      </div>
    </div>

    <div class="mt-4 grid grid-cols-1 md:grid-cols-3 gap-3">
      <div class="capsule-card">
        <strong>Live Choreography</strong>
        <p class="muted text-sm mt-1">Foot pulses mark the floor ‚Äî the trace maps your movement path in real time.</p>
      </div>
      <div class="capsule-card">
        <strong>Recording</strong>
        <p class="muted text-sm mt-1">MediaRecorder captures the session. Press Stop & Save to finalize the capsule.</p>
      </div>
      <div class="capsule-card">
        <strong>Privacy</strong>
        <p class="muted text-sm mt-1">Nothing leaves your device until you explicitly download or mint. You control the capsule.</p>
      </div>
    </div>
  </section>

  <!-- Preview / Capsule -->
  <section id="preview" class="capsule p-6 hidden">
    <div class="grid md:grid-cols-2 gap-6 items-start">
      <div>
        <h2 class="text-2xl font-semibold">üßæ Step Capsule Preview</h2>
        <p class="muted">A visual artifact of your movement will be saved with metadata.</p>

        <div class="mt-4">
          <video id="previewVideo" controls style="width:100%; border-radius:12px; background:#000;"></video>
        </div>

        <div class="mt-4 grid grid-cols-1 gap-3">
          <label class="text-xs muted">Name / Title</label>
          <input id="metaName" type="text" placeholder="Name of steps or your name" style="padding:10px; border-radius:8px; border:1px solid rgba(255,255,255,0.06); background:#071025; color:#eef2ff;" />

          <label class="text-xs muted mt-2">Location</label>
          <input id="metaLocation" type="text" placeholder="Kenya, Nairobi" style="padding:10px; border-radius:8px; border:1px solid rgba(255,255,255,0.06); background:#071025; color:#eef2ff;" />

          <label class="text-xs muted mt-2">Date</label>
          <input id="metaDate" type="date" style="padding:10px; border-radius:8px; border:1px solid rgba(255,255,255,0.06); background:#071025; color:#eef2ff;" />
        </div>

        <div class="mt-4 flex gap-3">
          <button id="downloadTracePng" class="btn btn-cta">‚¨áÔ∏è Download Trace PNG</button>
          <button id="downloadTraceSvg" class="btn btn-cta">‚¨áÔ∏è Download Trace SVG</button>
          <button id="downloadVideo" class="btn btn-muted">‚¨áÔ∏è Download Video</button>
        </div>
      </div>

      <div>
        <h3 class="text-lg font-semibold">Metadata</h3>
        <pre id="metaJson" class="json-preview">No metadata yet ‚Äî finalize the capsule to see JSON here.</pre>

        <div class="mt-4 flex gap-3">
          <button id="downloadMeta" class="btn btn-muted">‚¨áÔ∏è Download Metadata</button>
          <button id="mintBtn" class="btn btn-cta">ü™ô Mint Step Capsule (demo)</button>
        </div>
      </div>
    </div>
  </section>

  <!-- Gallery -->
  <section class="capsule p-6">
    <h3 class="text-2xl font-semibold">üñº Vaulted Movements</h3>
    <p class="muted">A living archive of choreography. Each capsule stores trace, video, and metadata.</p>

    <div id="gallery" class="mt-4 grid grid-cols-1 md:grid-cols-2 gap-4"></div>
  </section>

</main>

<script>
/*  Steps Recording Layer
    - MediaPipe Pose for foot detection
    - Live glowing footsteps + path trace
    - MediaRecorder to capture the session
    - Exports: Trace PNG, Trace SVG, Video (webm), Metadata JSON
    - Demo mint adds capsule to gallery
*/

// DOM refs
const startBtn = document.getElementById('startBtn');
const stopBtn  = document.getElementById('stopBtn');
const clearBtn = document.getElementById('clearBtn');
const stage = document.getElementById('stage');
const preview = document.getElementById('preview');
const gallery = document.getElementById('gallery');
const video = document.getElementById('video');
const previewVideo = document.getElementById('previewVideo');
const stepsOverlay = document.getElementById('stepsOverlay');
const traceCanvas = document.getElementById('traceCanvas');
const ctx = traceCanvas.getContext('2d');
const countdown = document.getElementById('countdown');
const statusText = document.getElementById('statusText');
const metaName = document.getElementById('metaName');
const metaLocation = document.getElementById('metaLocation');
const metaDate = document.getElementById('metaDate');
const metaJson = document.getElementById('metaJson');
const downloadTracePng = document.getElementById('downloadTracePng');
const downloadTraceSvg = document.getElementById('downloadTraceSvg');
const downloadVideoBtn = document.getElementById('downloadVideo');
const downloadMetaBtn = document.getElementById('downloadMeta');
const mintBtn = document.getElementById('mintBtn');

let stream = null;
let camera = null;
let mediaRecorder = null;
let recordedChunks = [];
let recording = false;

let pathPoints = []; // {x,y,time}
let lastStepAt = 0;

// Setup trace canvas size to match video area (will be resized on camera start)
function fitCanvasToVideo(){
  const rect = video.getBoundingClientRect();
  traceCanvas.width = rect.width;
  traceCanvas.height = rect.height;
  traceCanvas.style.width = rect.width + 'px';
  traceCanvas.style.height = rect.height + 'px';
}

// Utility: create a foot pulse DOM element at normalized coords
function createPulseAt(normX, normY){
  const step = document.createElement('div');
  step.className = 'footstep';
  // position relative to overlay
  step.style.left = (normX*100) + '%';
  step.style.top  = (normY*100) + '%';
  stepsOverlay.appendChild(step);
  setTimeout(()=> { if(step && step.remove) step.remove(); }, 1600);
}

// Trace drawing with fading background
function drawTrace(){
  // fade canvas slightly with translucent rect to create trailing/fading effect
  ctx.fillStyle = 'rgba(4,8,16,0.15)';
  ctx.fillRect(0,0,traceCanvas.width, traceCanvas.height);

  if(pathPoints.length < 2) return;

  ctx.save();
  ctx.lineWidth = 3;
  ctx.strokeStyle = 'rgba(124,58,237,0.95)';
  ctx.shadowBlur = 20;
  ctx.shadowColor = '#06b6d4';
  ctx.beginPath();
  for(let i=0;i<pathPoints.length;i++){
    const p = pathPoints[i];
    if(i===0) ctx.moveTo(p.x, p.y);
    else ctx.lineTo(p.x, p.y);
  }
  ctx.stroke();
  ctx.restore();

  // prune old points (keep trailing last N seconds)
  const now = Date.now();
  const TTL = 9000; // milliseconds to keep points
  pathPoints = pathPoints.filter(p => now - p.time < TTL);
}

// MediaPipe Pose setup
const pose = new Pose.Pose({
  locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5/${file}`
});
pose.setOptions({
  modelComplexity: 0,
  smoothLandmarks: true,
  enableSegmentation: false,
  minDetectionConfidence: 0.5,
  minTrackingConfidence: 0.5
});
pose.onResults(onPoseResults);

// Handle pose results: detect feet and draw pulses + append to path
function onPoseResults(results){
  if(!results.poseLandmarks) return;
  // get bounding rect of video element to map normalized coords
  const rect = video.getBoundingClientRect();
  // MediaPipe landmark indices
  const L_FOOT = Pose.POSE_LANDMARKS.LEFT_FOOT_INDEX;
  const R_FOOT = Pose.POSE_LANDMARKS.RIGHT_FOOT_INDEX;

  const candidates = [];
  [L_FOOT, R_FOOT].forEach(idx=>{
    const l = results.poseLandmarks[idx];
    if(l && l.visibility > 0.5){
      // normalized coords (x,y) in [0,1] where (0,0) top-left
      const nx = l.x; const ny = l.y;
      // create pulse and push to path but throttle to avoid flooding
      const now = Date.now();
      if(now - lastStepAt > 180){ // at most ~5-6 pulses per second
        createPulseAt(nx, ny);
        lastStepAt = now;
      }
      // map to canvas pixel coords (traceCanvas has same pixel size as video bounding)
      const px = nx * traceCanvas.width;
      const py = ny * traceCanvas.height;
      pathPoints.push({x:px, y:py, time:Date.now()});
    }
  });

  // draw current trace frame
  drawTrace();
}

// Set up camera using MediaPipe Camera utils
async function startCameraAndRecorder(){
  try {
    stream = await navigator.mediaDevices.getUserMedia({ video:{ facingMode: "user" }, audio: true });
    video.srcObject = stream;
    // wait for video metadata to set sizes
    await new Promise(r => video.onloadedmetadata = r);
    fitCanvasToVideo();

    // start MediaRecorder to capture video
    recordedChunks = [];
    try {
      mediaRecorder = new MediaRecorder(stream, {mimeType: 'video/webm; codecs=vp9'});
    } catch(e){
      mediaRecorder = new MediaRecorder(stream);
    }
    mediaRecorder.ondataavailable = (e) => { if(e.data && e.data.size) recordedChunks.push(e.data); };
    mediaRecorder.onstop = ()=> {
      const blob = new Blob(recordedChunks, { type: 'video/webm' });
      previewVideo.src = URL.createObjectURL(blob);
      downloadVideoBtn.href = previewVideo.src;
      downloadVideoBtn.download = 'step-capsule.webm';
    };
    mediaRecorder.start();

    // hook camera to mediapipe
    camera = new Camera(video, {
      onFrame: async () => { await pose.send({image: video}); },
      width: 640, height: 480
    });
    camera.start();
    recording = true;
    statusText.textContent = 'Recording';
    stopBtn.disabled = false;
    clearBtn.disabled = true;
  } catch (err){
    console.error(err);
    alert('Camera permission required. If denied, allow camera access and try again.');
    resetState();
  }
}

function stopCameraAndRecorder(){
  // stop MediaPipe camera loop
  if(camera && camera.stop) camera.stop();
  // stop tracks
  if(stream){
    stream.getTracks().forEach(t => t.stop());
  }
  // stop recorder
  if(mediaRecorder && mediaRecorder.state !== 'inactive') mediaRecorder.stop();
  recording = false;
  statusText.textContent = 'Stopped';
  stopBtn.disabled = true;
  clearBtn.disabled = false;
}

// UI actions
startBtn.addEventListener('click', async ()=>{
  stage.classList.remove('hidden');
  preview.classList.add('hidden');
  startBtn.disabled = true;
  countdownSequence();
  await startCameraAndRecorder();
});

stopBtn.addEventListener('click', ()=>{
  // finalize
  stopCameraAndRecorder();
  // prepare preview UI: show preview video + meta inputs and export buttons
  preview.classList.remove('hidden');
  stage.scrollIntoView({behavior:'smooth'});
  // build metadata preview
  metaDate.value = new Date().toISOString().slice(0,10);
  updateMetaJson();
});

clearBtn.addEventListener('click', ()=>{
  pathPoints = [];
  ctx.clearRect(0,0,traceCanvas.width, traceCanvas.height);
});

// Countdown animation before recording effect (visual only)
function countdownSequence(){
  let t = 3;
  countdown.textContent = t;
  const intv = setInterval(()=>{
    t--;
    countdown.textContent = t>0? t : '';
    if(t<=0){ clearInterval(intv); countdown.textContent = ''; }
  },1000);
}

// Export helpers

// Download trace PNG (raster)
downloadTracePng.addEventListener('click', ()=>{
  // Create a merged image: trace canvas over a transparent background same size as traceCanvas
  const pngData = traceCanvas.toDataURL('image/png');
  triggerDownload(pngData, 'choreography-trace.png');
});

// Generate SVG from pathPoints
function generateSVG(pathPointsList, w, h){
  if(!pathPointsList || pathPointsList.length < 2) {
    // return empty svg with a subtle background
    return `<?xml version="1.0" encoding="UTF-8"?>
      <svg xmlns="http://www.w3.org/2000/svg" width="${w}" height="${h}" viewBox="0 0 ${w} ${h}">
        <rect width="100%" height="100%" fill="none"/>
      </svg>`;
  }
  // simplify path: sample every Nth point to reduce size
  const sample = Math.max(1, Math.floor(pathPointsList.length/240));
  const pts = pathPointsList.filter((_,i)=> i % sample === 0);
  // construct path string
  const d = pts.map((p,i)=> `${i===0? 'M':'L'} ${Math.round(p.x)} ${Math.round(p.y)}`).join(' ');
  // svg with gradient stroke and glow via filter
  const svg = `<?xml version="1.0" encoding="UTF-8"?>
<svg xmlns="http://www.w3.org/2000/svg" width="${w}" height="${h}" viewBox="0 0 ${w} ${h}">
  <defs>
    <linearGradient id="g1" x1="0" x2="1">
      <stop offset="0%" stop-color="${hexToRgbA('--g1-start','#7c3aed')}" stop-opacity="1"/>
      <stop offset="100%" stop-color="${hexToRgbA('--g1-end','#06b6d4')}" stop-opacity="1"/>
    </linearGradient>
    <filter id="f1" x="-50%" y="-50%" width="200%" height="200%">
      <feGaussianBlur stdDeviation="8" result="b"/>
      <feMerge><feMergeNode in="b"/><feMergeNode in="SourceGraphic"/></feMerge>
    </filter>
  </defs>
  <rect width="100%" height="100%" fill="none"/>
  <path d="${d}" fill="none" stroke="url(#g1)" stroke-width="8" stroke-linecap="round" stroke-linejoin="round" filter="url(#f1)" opacity="0.95"/>
</svg>`;
  return svg;
}

// helper to download blob or dataurl
function triggerDownload(dataUrlOrBlob, filename){
  let url;
  if(typeof dataUrlOrBlob === 'string' && dataUrlOrBlob.startsWith('data:')){
    url = dataUrlOrBlob;
  } else if(dataUrlOrBlob instanceof Blob){
    url = URL.createObjectURL(dataUrlOrBlob);
  } else {
    // assume string content -> create blob
    const blob = new Blob([dataUrlOrBlob], {type:'text/plain'});
    url = URL.createObjectURL(blob);
  }
  const a = document.createElement('a');
  a.href = url;
  a.download = filename;
  document.body.appendChild(a);
  a.click();
  a.remove();
  // revoke object url after brief time
  setTimeout(()=> { if(url.startsWith('blob:')) URL.revokeObjectURL(url); }, 15000);
}

// Download SVG button
downloadTraceSvg.addEventListener('click', ()=>{
  // scale/translate based on current canvas pixel size
  const w = traceCanvas.width;
  const h = traceCanvas.height;
  const svgText = generateSVG(pathPoints, w, h);
  const blob = new Blob([svgText], {type:'image/svg+xml'});
  triggerDownload(blob, 'choreography-trace.svg');
});

// Download video
downloadVideoBtn.addEventListener('click', ()=>{
  // href and download set when mediaRecorder stops
  if(!previewVideo.src) alert('No video recorded yet.');
});

// Metadata JSON management
function updateMetaJson(){
  const metadata = {
    name: metaName.value || ('Step Capsule ‚Äî ' + new Date().toISOString()),
    description: 'Choreography trace + video recorded in Cultural Vault.',
    attributes: [
      {trait_type:'location', value: metaLocation.value || 'Unknown'},
      {trait_type:'date', value: metaDate.value || new Date().toISOString().slice(0,10)},
      {trait_type:'trace_points', value: pathPoints.length},
      {trait_type:'chain', value: 'Demo Chain'}
    ],
    created_at: new Date().toISOString(),
    files: {
      trace_png: 'DOWNLOAD_AFTER_EXPORT',
      trace_svg: 'DOWNLOAD_AFTER_EXPORT',
      video: 'DOWNLOAD_AFTER_EXPORT'
    }
  };
  metaJson.textContent = JSON.stringify(metadata, null, 2);
  return metadata;
}
